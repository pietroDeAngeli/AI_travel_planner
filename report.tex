\documentclass[journal]{IEEEtran}

\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
\title{AI Travel Planner}

\author{Pietro De Angeli}

% The paper headers
\markboth{Human Machine Dialogue Project - Universit√† di Trento}

% make the title area
\maketitle
\hfill \today

\section{Introduction}
This project presents an AI-powered conversational travel planning system that leverages large language models to assist users in creating personalized trip itineraries through natural dialogue. The system implements a modular pipeline architecture consisting of Natural Language Understanding (NLU), Dialogue Management (DM), and Natural Language Generation (NLG) components. Using Llama 3.1, the NLU module performs intent classification and slot extraction from user utterances, identifying travel preferences such as destination, dates, budget, and travel style. The dialogue manager maintains conversational state, tracks collected information, and determines appropriate system actions including dynamic slot filling and confirmation strategies. The NLG component generates contextually appropriate and natural responses through the language model. The system supports multi-turn conversations with capabilities for slot modification, clarification requests, and adaptive information gathering based on user intent. Integration with external APIs enables real-time retrieval of activities and accommodations to generate concrete travel plans. Evaluation demonstrates the system's effectiveness in handling complex travel planning dialogues while maintaining conversational coherence and user-friendliness.
I wish you the best of success.

\section{Conversation Design}

The travel planning system is designed to support natural, flexible dialogues that accommodate various user interaction styles and planning needs. The conversation design encompasses the types of dialogues the system handles and the key properties that enable effective human-machine interaction.

\subsection{Types of Dialogues}

The system supports multiple dialogue types that reflect different user goals and conversational patterns in travel planning scenarios. These dialogues are identified through intent recognition, where the system classifies user utterances into one of seven distinct intents using Llama 3.1 with careful prompt engineering and rule-based overrides for high-confidence patterns.

\subsubsection{Trip Planning Dialogues}

The core dialogue type is \textbf{trip planning} (PLAN\_TRIP intent), where users collaborate with the system to create personalized travel itineraries. These dialogues follow a structured information gathering process, collecting seven key parameters through natural conversation:

\begin{itemize}
\item \textbf{Destination}: Target city or location
\item \textbf{Travel dates}: Start date and end date defining trip duration
\item \textbf{Party size}: Number of travelers (num\_people)
\item \textbf{Travel style}: Preferred experience type (culture, relaxation, nightlife, walking, etc.)
\item \textbf{Accommodation type}: Lodging preference (hotel, hostel, apartment, etc.)
\item \textbf{Budget level}: Overall financial constraint (low, medium, high)
\end{itemize}

Trip planning dialogues are inherently mixed-initiative. Users may provide multiple pieces of information in a single utterance ("I want to visit Rome for 5 days in June with my family") or supply details incrementally across multiple turns. The system adapts its questions based on what information is already known, systematically requesting missing required slots while avoiding redundant questions.

The dialogue concludes when all required information is collected and confirmed, at which point the system retrieves real travel data from the Amadeus API and presents a structured itinerary with activity recommendations and accommodation options.

\subsubsection{Information Request Dialogues}

\textbf{Information request} dialogues (REQUEST\_INFORMATION intent) handle queries where users seek general knowledge about destinations without committing to a full planning process. Examples include asking about popular attractions in a city, typical costs, or specific venue information. These dialogues are typically shorter and do not require the complete slot-filling process of trip planning. The system acknowledges the request and provides relevant information when available, or explains limitations when data is unavailable.

\subsubsection{Comparison Dialogues}

Users often need to make choices between alternatives during travel planning. \textbf{Comparison dialogues} (COMPARE\_OPTIONS intent) address requests to evaluate multiple options based on specific criteria. Users might compare cities as potential destinations, different accommodation types, or activity categories. The system extracts the entities being compared (option1, option2) and the comparison criteria, then provides structured comparisons to aid decision-making.

\subsubsection{Confirmation and Modification Dialogues}

Two specialized dialogue types support verification and correction of collected information:

\textbf{Confirmation dialogues} (CONFIRM\_DETAILS intent) occur when the system explicitly requests user validation of gathered details before proceeding with plan generation. These follow a simple yes/no pattern where users either confirm correctness or indicate needed changes.

\textbf{Modification dialogues} involve a multi-turn subdialogue structure when users want to change previously provided information. The system first asks which detail needs modification (ASK\_WHICH\_SLOT\_TO\_CHANGE), identifies the target slot through user response or heuristic matching, then requests the new value (ASK\_NEW\_VALUE\_FOR\_SLOT). After updating the information, confirmation status is reset, ensuring the user validates the revised details before plan generation.

\subsubsection{Social and Control Dialogues}

The system handles \textbf{greeting exchanges} (GREETING intent) to establish rapport and acknowledge conversation openings, and \textbf{closing dialogues} (END\_DIALOGUE intent) when users signal their intention to terminate the interaction. These social protocols contribute to natural, human-like conversation flow.

\subsubsection{Out-of-Domain Handling}

When user input falls outside the system's capabilities, it is classified as \textbf{out-of-domain} (OOD intent). Rather than attempting to process irrelevant requests or hallucinating responses, the system explicitly asks for clarification or gracefully indicates it cannot address the query, maintaining transparency about its limitations.

\subsection{Interaction Properties}

The system exhibits several key properties that enable effective mixed-initiative dialogue and flexible information gathering.

\subsubsection{Multi-turn Conversation Management}

The dialogue manager maintains persistent state across multiple conversational turns, tracking collected information, current intent, and dialogue flow position. This enables coherent extended conversations where context accumulates naturally. The state representation includes:

\begin{itemize}
\item All collected slot values (user information)
\item Current and task-level intents
\item Confirmation status
\item Slot modification state (which slot is being changed)
\item Generated travel plans (activities and accommodations)
\item Internal dialogue state for subdialogue handling
\end{itemize}

Dialogue history is maintained and provided as context to the NLU module, allowing intent classification and slot extraction to consider previous turns. This context awareness prevents misunderstandings and enables anaphoric references ("change the dates" implicitly refers to previously mentioned trip dates).

\subsubsection{Dynamic Slot Filling Strategy}

Rather than following rigid form-filling patterns, the system employs flexible slot filling that adapts to user input. When users provide information voluntarily, the system accepts and integrates it without prompting. When information is missing, the dialogue manager identifies gaps and generates natural requests for specific slots through the NLG module.

The slot filling strategy is \textit{intent-aware}: different intents require different subsets of slots. For trip planning, all seven parameters are required before plan generation. For information requests, only the destination and entity type may be needed. This selective approach avoids unnecessary questions and keeps dialogues efficient.

Importantly, slots can be provided in any order, and the system gracefully handles partial information. If a user says "I want to go to Paris" without mentioning dates, the system acknowledges the destination and asks about timing, rather than rejecting the incomplete input.

\subsubsection{Confirmation and Error Recovery}

Before committing to potentially expensive API calls and plan generation, the system implements a \textit{confirmation strategy}. Once all required slots are filled, the dialogue manager selects ASK\_CONFIRMATION as the action, and the NLG module generates a summary of collected details for user verification. This checkpoint prevents downstream errors from misunderstood or incorrectly extracted information.

When users identify errors during confirmation, the system enters error recovery mode through the modification subdialogue flow. This mechanism supports user-initiated corrections at any point without requiring dialogue restart. After any modification, confirmation status is reset, ensuring users validate the complete updated information.

\subsubsection{Clarification Requests}

Ambiguous utterances, out-of-scope requests, or low-confidence interpretations trigger clarification requests (ASK\_CLARIFICATION action). Rather than guessing or making assumptions that could lead to incorrect plans, the system explicitly asks users to rephrase or provide additional detail. This transparency helps maintain user trust and prevents compounding errors.

\subsubsection{Natural Language Generation}

All system responses are generated dynamically by Llama 3.1 rather than using static templates. The NLG module receives the dialogue manager's selected action, current state, and relevant context, then produces contextually appropriate, conversational responses. This approach provides several advantages:

\begin{itemize}
\item \textbf{Variability}: Repeated requests for the same information use different phrasings, avoiding robotic repetition
\item \textbf{Context integration}: Responses naturally incorporate previously discussed details
\item \textbf{Tone consistency}: All utterances maintain a helpful, friendly conversational style
\item \textbf{Adaptability}: The system can adjust formality and complexity based on user language patterns
\end{itemize}

The LLM is instructed to maintain conversational naturalness while avoiding technical jargon about internal states, intents, or system architecture. Users experience fluid dialogue rather than perceiving the underlying slot-filling machinery.

\subsubsection{External Knowledge Integration}

The system integrates real-world travel data through the Amadeus API, retrieving activities and accommodations based on confirmed user preferences. API queries are constructed using collected slots: destination determines location searches, dates and party size filter accommodation availability, and budget level influences hotel ratings. Retrieved data is formatted into readable presentations with ratings, prices, descriptions, and other relevant details.

This external knowledge integration transforms the system from a pure conversational agent into a practical planning tool that provides actionable recommendations grounded in real availability and pricing.

\subsubsection{Dialogue Flow Management}

A rule-based dialogue policy maps the combination of recognized intent and current state to system actions. The policy implements strategic decision-making:

\begin{itemize}
\item Prioritize information gathering before plan generation
\item Request missing slots systematically
\item Confirm details before expensive operations
\item Handle slot modifications through dedicated subdialogues
\item Acknowledge updates and maintain conversational continuity
\end{itemize}

The policy supports ten distinct system actions that cover greeting, clarification, slot requests, confirmations, acknowledgments, plan presentation, modification handling, and closing. This repertoire enables the system to navigate complex conversational paths while maintaining coherent goal-directed behavior.

A typical successful interaction demonstrates these properties working together: the user initiates with partial information, the system acknowledges and requests missing details across multiple turns, confirms the complete information, retrieves real travel data, presents formatted recommendations, and handles any post-presentation modifications or clarifications before concluding the conversation.

\section{Conversation Model}

The conversation model describes the technical architecture and processing flow that implements the conversation design principles described in the previous section. The system follows a modular pipeline architecture with specialized components for understanding user input, managing dialogue state, and generating responses.

\subsection{Pipeline}

The travel planning system implements a classic NLU-DM-NLG pipeline architecture, where each component performs a specialized function in the dialogue processing flow.

The \textbf{pipeline execution} follows these steps for each user utterance:

\begin{enumerate}
\item \textbf{Input Processing}: User text is received and added to dialogue history
\item \textbf{Natural Language Understanding}: The NLU module analyzes the utterance in context, classifying the intent and extracting slot values
\item \textbf{State Update}: The dialogue manager updates the dialogue state with new information from recognized slots
\item \textbf{Decision Making}: The DM's policy function maps the current intent and state to a system action
\item \textbf{Natural Language Generation}: The NLG module generates an appropriate response based on the selected action and current state
\item \textbf{Output Delivery}: The response is presented to the user and added to dialogue history
\end{enumerate}

The pipeline maintains \textbf{dialogue history} as a list of turn pairs (user utterances and system responses), which provides context for subsequent processing. The NLU module receives recent history to resolve ambiguities and handle anaphoric references. The NLG module accesses history to maintain conversational coherence and avoid repetitive phrasing.

\textbf{State persistence} is maintained through a DialogueState object that carries information across turns. This object contains user information (all collected slots), intent tracking (current and task-level intents), confirmation status, and generated plans. State updates occur after NLU processing, and the updated state informs DM decision-making.

The architecture uses \textbf{Llama 3.1} as the underlying language model for both NLU and NLG functions. Rather than training specialized models, the system leverages the LLM's few-shot learning capabilities through careful prompt engineering. Each module constructs prompts that include task descriptions, schema definitions, rules, dialogue context, and explicit output format specifications.

\textbf{External API integration} occurs within the pipeline after the DM decides to generate a travel plan. When the action is PROPOSE\_TRIP\_PLAN, the main loop queries the Amadeus API for activities and accommodations before invoking NLG. This ensures the NLG module has access to real travel data when formatting the response.

The pipeline executes synchronously, processing one turn at a time. Each step completes before the next begins, ensuring consistency between state updates and decision-making. While this approach has higher latency than parallel processing, it prevents race conditions and maintains deterministic dialogue flow.

\subsection{Segmenter}

The segmenter component is responsible for preprocessing user input and extracting relevant information from utterances. In this system, segmentation occurs primarily within the NLU module through a combination of LLM-based understanding and rule-based pattern matching.

\subsubsection{Input Preprocessing}

User utterances undergo minimal preprocessing before analysis:

\begin{itemize}
\item \textbf{Whitespace normalization}: Leading and trailing whitespace is stripped
\item \textbf{Empty input handling}: Blank utterances are skipped without pipeline processing
\item \textbf{Hard exit detection}: Commands like "stop", "exit", "quit", and "goodbye" trigger immediate dialogue termination
\end{itemize}

The system deliberately avoids aggressive preprocessing (tokenization, lemmatization, stemming) that could lose information. Instead, raw text is passed to the LLM, which handles linguistic variation through its pre-trained language understanding.

\subsubsection{Context Segmentation}

Dialogue history is segmented to provide relevant context without overwhelming the LLM's context window:

\begin{itemize}
\item \textbf{Recency focus}: Only the last 2 turn pairs are included as explicit context for NLU
\item \textbf{Last assistant message extraction}: The most recent system response is identified and provided separately, as it often contains questions or prompts that contextualize the user's reply
\item \textbf{Format standardization}: History is formatted as "ROLE: content" pairs for clarity
\end{itemize}

This windowed approach balances context provision with computational efficiency, ensuring the LLM focuses on immediately relevant information.

\subsubsection{Intent-Slot Segmentation}

The NLU module performs semantic segmentation by decomposing utterances into intent and slot components. This segmentation is guided by the schema definition:

\begin{itemize}
\item \textbf{Intent space}: Seven possible intents (PLAN\_TRIP, REQUEST\_INFORMATION, COMPARE\_OPTIONS, CONFIRM\_DETAILS, GREETING, END\_DIALOGUE, OOD)
\item \textbf{Slot space}: Fourteen possible slots across all intents, with intent-specific constraints
\item \textbf{Intent-slot mapping}: Each intent is associated with a valid slot subset, ensuring extracted information is semantically appropriate
\end{itemize}

The LLM performs this segmentation by analyzing the utterance and outputting a structured JSON object. The system validates the output format, ensuring only schema-compliant intents and slots are accepted.

\subsubsection{Rule-Based Override}

Before invoking the LLM, a rule-based quick intent classifier checks for high-confidence patterns:

\begin{itemize}
\item \textbf{Farewell detection}: Regular expressions identify variations of "bye", "goodbye", "stop", "exit", "quit"
\item \textbf{Greeting detection}: Patterns match "hi", "hello", "hey"
\item \textbf{Confirmation detection}: In response to system confirmation requests, patterns identify "yes", "no", "correct", "okay", and variations
\end{itemize}

When these patterns match, the intent is assigned directly without LLM processing, reducing latency and ensuring reliable handling of simple, high-frequency utterances.

\subsection{Intents}

The intent recognition system categorizes user utterances into one of seven distinct intents, each representing a different user goal or dialogue function. Intent classification drives the dialogue manager's policy decisions and determines which slots are relevant for extraction.

\subsubsection{Intent Schema}

Each intent is formally defined with associated slots and recognition rules:

\textbf{PLAN\_TRIP} is the primary task intent, recognized when users express trip planning goals or provide trip-related information. Associated slots include destination, start\_date, end\_date, num\_people, travel\_style, accommodation\_type, and budget\_level. The system uses inclusive recognition: any mention of these parameters triggers PLAN\_TRIP, even for incremental updates or modifications.

\textbf{REQUEST\_INFORMATION} handles queries about destinations or travel entities without commitment to planning. Associated slots are destination, entity\_type (hotels, flights, activities, events), and budget\_constraint. Recognition rules distinguish this from PLAN\_TRIP by checking for interrogative structures and absence of personal trip details.

\textbf{COMPARE\_OPTIONS} captures requests to evaluate alternatives. Slots include option1, option2, and criteria (comparison dimension). Recognition patterns include explicit comparison language ("compare", "versus", "which is better") and listing of alternatives.

\textbf{CONFIRM\_DETAILS} is recognized only in specific contexts: when the system has explicitly requested confirmation and the user responds with affirmation or negation. This intent has no associated slots, as it represents a yes/no response to system prompts.

\textbf{GREETING} handles conversation openings and social exchanges. No slots are extracted. Recognition patterns include greeting phrases and conversation initiators.

\textbf{END\_DIALOGUE} signals user intention to terminate the conversation. No slots. Recognition is based on farewell expressions and explicit exit commands.

\textbf{OOD} (Out of Domain) serves as a fallback for utterances that don't match any defined intent or fall outside the system's capabilities. No slots. The LLM assigns this intent when it cannot confidently classify input into other categories.

\subsubsection{Intent Recognition Process}

Intent classification follows a two-stage process:

\textbf{Stage 1: Rule-based quick classification} checks for patterns with near-certainty. If a match is found (e.g., "bye" matching END\_DIALOGUE), the intent is assigned immediately and only slots valid for that intent are initialized (typically with null values for non-task intents).

\textbf{Stage 2: LLM-based classification} is invoked when rule-based matching fails. The system constructs a prompt containing:

\begin{itemize}
\item System message defining the NLU task and listing valid intents and slots
\item Intent-slot constraint definitions (INTENT\_SLOTS mapping)
\item Explicit recognition rules for each intent
\item Recent dialogue history (last 2 turns)
\item The last assistant message (often contains context-critical questions)
\item The current user utterance
\item Output format specification (JSON with intent and slots keys)
\end{itemize}

The LLM generates a response, which is parsed to extract the JSON structure. The predicted intent is validated against the intent schema, and any invalid intent is replaced with OOD.

\subsubsection{Intent Constraints and Validation}

Several mechanisms ensure intent recognition quality:

\textbf{Intent-slot constraints} enforce that only relevant slots are extracted for each intent. After classification, the system filters extracted slots to include only those in the intent's valid slot set (INTENT\_SLOTS mapping). This prevents semantic inconsistencies like extracting travel dates for a GREETING intent.

\textbf{Context-aware recognition} uses dialogue history to disambiguate utterances. For example, "change it" in isolation is ambiguous, but following a confirmation request, context helps recognize the user's intention to modify information.

\textbf{Explicit rules in prompts} guide the LLM's classification decisions. For instance, the PLAN\_TRIP rule specifies recognition for any trip information provision, including modifications, ensuring consistent behavior even for varied linguistic expressions.

\textbf{Null handling} requires the LLM to output null for unknown slot values rather than guessing or hallucinating. This prevents the system from inventing information and maintains data integrity.

\subsubsection{Intent Transitions}

The dialogue supports intent transitions where users shift between different goals:

\begin{itemize}
\item Users can move from REQUEST\_INFORMATION to PLAN\_TRIP when casual inquiry evolves into concrete planning
\item COMPARE\_OPTIONS may precede PLAN\_TRIP when users are deciding on destinations
\item CONFIRM\_DETAILS typically follows PLAN\_TRIP after information gathering completes
\item END\_DIALOGUE can occur at any point when users choose to exit
\end{itemize}

The dialogue manager tracks both current\_intent (most recent) and task\_intent (overarching goal). This distinction allows the system to handle confirmations, clarifications, and modifications while maintaining focus on the primary task.

\section{Evaluation}



\section{Conclusion}



\appendices
\section{Proof of the First Zonklar Equation}
Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
\section{}
Appendix two text goes here.


% use section* for acknowledgment
\section*{Acknowledgment}


The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



\begin{thebibliography}{1}

\bibitem{IEEEhowto:kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

\end{thebibliography}

\begin{IEEEbiographynophoto}{Jane Doe}
Biography text here.
\end{IEEEbiographynophoto}


\end{document}


